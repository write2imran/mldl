{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82306c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79883000",
   "metadata": {},
   "source": [
    "### Define Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dd7d0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "def get_data():\n",
    "    train_X = np.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "    train_Y = np.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "    dtype = torch.FloatTensor\n",
    "    X = Variable(torch.from_numpy(train_X).type(dtype),requires_grad=False).view(17,1)\n",
    "    y = Variable(torch.from_numpy(train_Y).type(dtype),requires_grad=False)\n",
    "    return X,y\n",
    "\n",
    "def plot_variable(x,y,z='',**kwargs):\n",
    "    l = []\n",
    "    for a in [x,y]:\n",
    "        if type(a) == Variable:\n",
    "            l.append(a.data.numpy())\n",
    "    plt.plot(l[0],l[1],z,**kwargs)\n",
    "\n",
    "def get_weights():\n",
    "    w = Variable(torch.randn(1),requires_grad = True)\n",
    "    b = Variable(torch.randn(1),requires_grad=True)\n",
    "    return w,b\n",
    "\n",
    "def simple_network(x):\n",
    "    y_pred = torch.matmul(x,w)+b\n",
    "    return y_pred\n",
    "\n",
    "def loss_fn(y,y_pred):\n",
    "    loss = (y_pred-y).pow(2).sum()\n",
    "    for param in [w,b]:\n",
    "        if not param.grad is None: param.grad.data.zero_()\n",
    "    loss.backward()\n",
    "    \n",
    "    backLoss = (y_pred-y).sum()*2\n",
    "    print (\"backLoss: \", backLoss.item())\n",
    "    print(\"loss.grad\", loss.grad)\n",
    "    #return loss.data[0]\n",
    "    return loss\n",
    "\n",
    "\n",
    "def optimize(learning_rate):\n",
    "    w.data -= learning_rate * w.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cca0b",
   "metadata": {},
   "source": [
    "### Retreive Data and Weigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e07c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = get_data()               # x - represents training data,y - represents target variables\n",
    "w,b = get_weights()           # w,b - Learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071ead1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8b7cfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot X and Y\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x25c581e7fa0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQfUlEQVR4nO3dcWyc9X3H8c+nxhPX0uk2xRvYAbJpyNtKRI0sCkOaEEUy3dCwIiYxabSqJkUwtMHEPM38QdW/MskT2komoqx0BQ0xVWC5CME81FEV/iCdEwdMCNZQ15acs2GoHMh26hzvuz98Bse9s++cOz/P/Z73Szr5/Nwvd1+dzp88/j7f57EjQgCA7veJrAsAALQHgQ4AiSDQASARBDoAJIJAB4BEXJTVC+/atSv27NmT1csDQFc6evToexHRV++xzAJ9z549mpmZyerlAaAr2f5Ro8douQBAIgh0AEjEloFu+2Lb37f9mu0Ttr9aZ81Nts/YPl67PdSZcgEAjTTTQ/+ppJsj4qztXkmv2H4hIl7dsO7liLit/SUCAJqxZaDH6sVezta+7a3duAAMAORMU1MutnskHZX0a5L+LiKO1Fl2g+3XJC1I+vOIOFHnefZL2i9JV1xxxbaLBoBuNDVb0cT0vBaWquovlzQ2MqjRoYG2PX9TB0UjYiUiPitpt6TrbF+9YckxSVdGxDWSHpE01eB5DkfEcEQM9/XVHaMEgCRNzVY0PjmnylJVIamyVNX45JymZitte42WplwiYknSdyXdumH7BxFxtnb/eUm9tne1qUYA6HoT0/OqLq+ct626vKKJ6fm2vUYzUy59tsu1+yVJt0h6a8OaS227dv+62vO+37YqAaDLLSxVW9q+Hc300C+T9Hitj/4JSd+KiOds3y1JEXFI0h2S7rF9TlJV0p3BX84AgI/0l0uq1Anv/nKpba/RzJTL65KG6mw/tO7+QUkH21YVACRmbGRQ45Nz57VdSr09GhsZbNtrZHYtFwAokrVplk5OuRDoALBDRocG2hrgG3EtFwBIBHvoAJLV6RN58oZAB5CktRN51g5Crp3IIynZUKflAiBJO3EiT94Q6ACStBMn8uQNgQ4gSY1O2GnniTx5Q6ADSNLYyKBKvT3nbWv3iTx5w0FRAEnaiRN58oZAB5CsTp/Ikze0XAAgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASARz6EALinY5VnQXAh1oUhEvx4ruQssFaFIRL8eK7kKgA00q4uVY0V0IdKBJRbwcK7oLgQ40qYiXY0V34aAo0KQiXo4V3YVAB1pQtMuxorvQcgGARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgERsGei2L7b9fduv2T5h+6t11tj212y/bft129d2plwAQCPNnPr/U0k3R8RZ272SXrH9QkS8um7NFyRdVbt9TtKjta8AgB2y5R56rDpb+7a3dosNy26X9ERt7auSyrYva2+pAIDNNNVDt91j+7ikdyW9GBFHNiwZkPTOuu9P1bZtfJ79tmdszywuLm6zZABAPU0FekSsRMRnJe2WdJ3tqzcscb1/Vud5DkfEcEQM9/X1tVwsAKCxli6fGxFLtr8r6VZJb6x76JSky9d9v1vSwgVXB6CQpmYrXHd+G5qZcumzXa7dL0m6RdJbG5Y9K+mLtWmX6yWdiYjT7S4WQPqmZisan5xTZamqkFRZqmp8ck5Ts5WsS8u9Zloul0l6yfbrkv5Nqz3052zfbfvu2prnJf1A0tuS/l7SH3ekWgDJm5ieV3V55bxt1eUVTUzPZ1RR99iy5RIRr0saqrP90Lr7Iene9pYGoIgWlqotbcfH+BN0QOK6rR/dXy6pUie8+8ulDKrpLpz6DySsG/vRYyODKvX2nLet1NujsZHBjCrqHgQ6kLBu7EePDg3owL69GiiXZEkD5ZIO7Nub698q8oKWC5Cwbu1Hjw4NEODbwB46kLBGfWf60Wki0IGE0Y8uFlouQIfkYbpk7fWyrgM7g0AHOmBtumTtgOTadImkTEKdAC8GWi5AB3TjdAm6H4EOdEC3TpeguxHoQAcwXYIsEOhABzBdgixwULQg8jBxUSRMlyALBHoB5GniokiYLsFOo+VSAExcAMVAoBcAExdAMRDoBcDEBVAMBHoBMHEBFAMHRQuAiQugGAj0gmDiAkgfLRcASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABLBHDqSx6WDURQEOpLGpYNRJLRckDQuHYwiIdCRNC4djCIh0JE0Lh2MIiHQkTQuHYwi4aAokpbSpYOZ1sFWCHQkL4VLBzOtg2Zs2XKxfbntl2yftH3C9n111txk+4zt47XbQ50pFygmpnXQjGb20M9JeiAijtn+tKSjtl+MiDc3rHs5Im5rf4kAmNZBM7bcQ4+I0xFxrHb/Q0knJfE7HrCDmNZBM1qacrG9R9KQpCN1Hr7B9mu2X7D9mQb/fr/tGdszi4uLrVcLFBTTOmhG04Fu+xJJz0i6PyI+2PDwMUlXRsQ1kh6RNFXvOSLicEQMR8RwX1/fNksGimd0aEAH9u3VQLkkSxool3Rg314OiOI8joitF9m9kp6TNB0RDzex/oeShiPivUZrhoeHY2ZmpoVSAQC2j0bEcL3HmplysaTHJJ1sFOa2L62tk+3ras/7/vZLBgC0qpkplxsl3SVpzvbx2rYHJV0hSRFxSNIdku6xfU5SVdKd0cyuP9AAJ9EArdsy0CPiFUneYs1BSQfbVRSKjZNogO3hWi7IHU6iAbaHQEfucBINsD0EOnKHk2iA7SHQkTucRANsD1dbRO6kdMlbYCcR6MilFC55C+w0Wi4AkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARBDoAJAIAh0AEkGgA0AiCHQASASBDgCJINABIBEEOgAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4Aibgo6wKAqdmKJqbntbBUVX+5pLGRQY0ODWRdFtB1CHRkamq2ovHJOVWXVyRJlaWqxifnJIlQB1pEywWZmpie/yjM11SXVzQxPZ9RRUD3ItCRqYWlakvbATRGoCNT/eVSS9sBNEagI1NjI4Mq9fact63U26OxkcGMKgK6FwdFkam1A59MuQAXjkBH5kaHBghwoA22bLnYvtz2S7ZP2j5h+746a2z7a7bftv267Ws7Uy4AoJFm9tDPSXogIo7Z/rSko7ZfjIg31635gqSrarfPSXq09hUAsEO23EOPiNMRcax2/0NJJyVt/P34dklPxKpXJZVtX9b2agEADbU05WJ7j6QhSUc2PDQg6Z1135/Sz4a+bO+3PWN7ZnFxscVSAQCbaTrQbV8i6RlJ90fEBxsfrvNP4mc2RByOiOGIGO7r62utUgDAppoKdNu9Wg3zJyNiss6SU5IuX/f9bkkLF14eAKBZzUy5WNJjkk5GxMMNlj0r6Yu1aZfrJZ2JiNNtrBMAsIVmplxulHSXpDnbx2vbHpR0hSRFxCFJz0v6HUlvS/ofSV9ue6UAgE1tGegR8Yrq98jXrwlJ97arKABA67iWCwAkgkAHgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIkg0AEgEQQ6ACSCQAeARDTzN0XRpKnZiiam57WwVFV/uaSxkUGNDg1kXRZ2EJ8BZIlAb5Op2YrGJ+dUXV6RJFWWqhqfnJMkfqALgs8AskbLpU0mpuc/+kFeU11e0cT0fEYVYafxGUDWCPQ2WViqtrQd6eEzgKzRcmmT/nJJlTo/uP3lUgbV5E8Rest8BpA19tDbZGxkUKXenvO2lXp7NDYymFFF+bHWW64sVRX6uLc8NVvJurS24jOArBHobTI6NKAD+/ZqoFySJQ2USzqwb29ye6HbUZTeMp8BZI2WSxuNDg3ww1tHkXrLfAaQJfbQ0XGNesj0loH2ItDRcfSWgZ1BywUdt9aCSH3KBcgagZ6IvI8F0lsGOo9ATwCnnAOQ6KEnoShjgQA2R6AnoEhjgQAaI9ATwFggAIlATwJjgQCkJgLd9jdsv2v7jQaP32T7jO3jtdtD7S8Tm+GUcwBSc1Mu35R0UNITm6x5OSJua0tF2BbGAgFsuYceEd+T9JMdqAUAcAHa1UO/wfZrtl+w/ZlGi2zvtz1je2ZxcbFNLw0AkNoT6MckXRkR10h6RNJUo4URcTgihiNiuK+vrw0vDQBYc8GBHhEfRMTZ2v3nJfXa3nXBlQEAWnLBgW77Utuu3b+u9pzvX+jzAgBas+WUi+2nJN0kaZftU5K+IqlXkiLikKQ7JN1j+5ykqqQ7IyI6VjEAoK4tAz0i/mCLxw9qdawRAJAhzhQFgEQQ6ACQCAIdABJBoANAIgh0AEgEgQ4AiSDQASARBDoAJIJAB4BENPMHLrDO1GxFE9PzWliqqr9c0tjIIH9YAkAuEOgtmJqtaHxyTtXlFUlSZamq8ck5SSLUAWSOlksLJqbnPwrzNdXlFU1Mz2dUEQB8jEBvwcJStaXtALCTCPQW9JdLLW0HgJ1EoLdgbGRQpd6e87aVens0NjKYUUUA8DEOirZg7cAnUy4A8qirAj0PI4OjQwMEOIBc6ppAZ2QQADbXNT10RgYBYHNdE+iMDALA5rom0BkZBIDNdU2gMzIIAJvrmoOijAwCwOa6JtAlRgYBYDNd03IBAGyOQAeARBDoAJAIAh0AEkGgA0AiHBHZvLC9KOlHTSzdJem9DpfTjXhfGuO9qY/3pbFuem+ujIi+eg9kFujNsj0TEcNZ15E3vC+N8d7Ux/vSWCrvDS0XAEgEgQ4AieiGQD+cdQE5xfvSGO9NfbwvjSXx3uS+hw4AaE437KEDAJpAoANAInIZ6LYvt/2S7ZO2T9i+L+ua8sR2j+1Z289lXUue2C7bftr2W7XPzg1Z15QXtv+s9rP0hu2nbF+cdU1Zsf0N2+/afmPdtl+0/aLtf699/YUsa9yuXAa6pHOSHoiI35B0vaR7bf9mxjXlyX2STmZdRA79raR/johfl3SNeI8kSbYHJP2ppOGIuFpSj6Q7s60qU9+UdOuGbX8p6TsRcZWk79S+7zq5DPSIOB0Rx2r3P9TqDyYXQpdke7ek35X09axryRPbPy/ptyU9JkkR8b8RsZRpUflykaSS7YskfVLSQsb1ZCYivifpJxs23y7p8dr9xyWN7mRN7ZLLQF/P9h5JQ5KOZFxKXvyNpL+Q9H8Z15E3vyppUdI/1NpRX7f9qayLyoOIqEj6a0k/lnRa0pmI+Jdsq8qdX46I09LqDqWkX8q4nm3JdaDbvkTSM5Luj4gPsq4na7Zvk/RuRBzNupYcukjStZIejYghSf+tLv21ud1q/eDbJf2KpH5Jn7L9h9lWhU7IbaDb7tVqmD8ZEZNZ15MTN0r6Pds/lPRPkm62/Y/ZlpQbpySdioi13+Se1mrAQ7pF0n9ExGJELEualPRbGdeUN/9l+zJJqn19N+N6tiWXgW7bWu2FnoyIh7OuJy8iYjwidkfEHq0e1PrXiGBPS1JE/Kekd2wP1jZ9XtKbGZaUJz+WdL3tT9Z+tj4vDhhv9KykL9Xuf0nStzOsZdvy+keib5R0l6Q528dr2x6MiOezKwld4E8kPWn75yT9QNKXM64nFyLiiO2nJR3T6gTZrBI51X07bD8l6SZJu2yfkvQVSX8l6Vu2/0ir/wH+fnYVbh+n/gNAInLZcgEAtI5AB4BEEOgAkAgCHQASQaADQCIIdABIBIEOAIn4f8KZJS/Lq1dDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (\"Plot X and Y\")\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff0b186a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W and B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1.1724963188171387, 0.5144639611244202)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"W and B\")\n",
    "w.item(), b.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fdb7eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Learning Rate: \n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Learning Rate: \")\n",
    "print(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87507567",
   "metadata": {},
   "source": [
    "### Meat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "599ee520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backLoss:  -311.2785339355469\n",
      "loss.grad None\n",
      "Actual Loss:  1616.5347900390625\n",
      "backLoss:  -263.5344543457031\n",
      "loss.grad None\n",
      "backLoss:  -223.12127685546875\n",
      "loss.grad None\n",
      "backLoss:  -188.9134063720703\n",
      "loss.grad None\n",
      "backLoss:  -159.95802307128906\n",
      "loss.grad None\n",
      "backLoss:  -135.4486083984375\n",
      "loss.grad None\n",
      "backLoss:  -114.70255279541016\n",
      "loss.grad None\n",
      "backLoss:  -97.14193725585938\n",
      "loss.grad None\n",
      "backLoss:  -82.27767181396484\n",
      "loss.grad None\n",
      "backLoss:  -69.69574737548828\n",
      "loss.grad None\n",
      "backLoss:  -59.045719146728516\n",
      "loss.grad None\n",
      "backLoss:  -50.03094482421875\n",
      "loss.grad None\n",
      "backLoss:  -42.40033721923828\n",
      "loss.grad None\n",
      "backLoss:  -35.941368103027344\n",
      "loss.grad None\n",
      "backLoss:  -30.474124908447266\n",
      "loss.grad None\n",
      "backLoss:  -25.84634017944336\n",
      "loss.grad None\n",
      "backLoss:  -21.929115295410156\n",
      "loss.grad None\n",
      "backLoss:  -18.613346099853516\n",
      "loss.grad None\n",
      "backLoss:  -15.806684494018555\n",
      "loss.grad None\n",
      "backLoss:  -13.430953979492188\n",
      "loss.grad None\n",
      "backLoss:  -11.4199857711792\n",
      "loss.grad None\n",
      "backLoss:  -9.71777629852295\n",
      "loss.grad None\n",
      "backLoss:  -8.2769136428833\n",
      "loss.grad None\n",
      "backLoss:  -7.057269096374512\n",
      "loss.grad None\n",
      "backLoss:  -6.024877548217773\n",
      "loss.grad None\n",
      "backLoss:  -5.1509833335876465\n",
      "loss.grad None\n",
      "backLoss:  -4.411252021789551\n",
      "loss.grad None\n",
      "backLoss:  -3.785083770751953\n",
      "loss.grad None\n",
      "backLoss:  -3.255037546157837\n",
      "loss.grad None\n",
      "backLoss:  -2.806361198425293\n",
      "loss.grad None\n",
      "backLoss:  -2.4265565872192383\n",
      "loss.grad None\n",
      "backLoss:  -2.1050498485565186\n",
      "loss.grad None\n",
      "backLoss:  -1.832881212234497\n",
      "loss.grad None\n",
      "backLoss:  -1.6024887561798096\n",
      "loss.grad None\n",
      "backLoss:  -1.4074482917785645\n",
      "loss.grad None\n",
      "backLoss:  -1.2423338890075684\n",
      "loss.grad None\n",
      "backLoss:  -1.1025536060333252\n",
      "loss.grad None\n",
      "backLoss:  -0.984215497970581\n",
      "loss.grad None\n",
      "backLoss:  -0.8840236663818359\n",
      "loss.grad None\n",
      "backLoss:  -0.799199104309082\n",
      "loss.grad None\n",
      "backLoss:  -0.7273755073547363\n",
      "loss.grad None\n",
      "backLoss:  -0.6665570735931396\n",
      "loss.grad None\n",
      "backLoss:  -0.6150579452514648\n",
      "loss.grad None\n",
      "backLoss:  -0.5714492797851562\n",
      "loss.grad None\n",
      "backLoss:  -0.5345141887664795\n",
      "loss.grad None\n",
      "backLoss:  -0.5032250881195068\n",
      "loss.grad None\n",
      "backLoss:  -0.47672295570373535\n",
      "loss.grad None\n",
      "backLoss:  -0.4542663097381592\n",
      "loss.grad None\n",
      "backLoss:  -0.4352390766143799\n",
      "loss.grad None\n",
      "backLoss:  -0.419109582901001\n",
      "loss.grad None\n",
      "backLoss:  -0.4054415225982666\n",
      "loss.grad None\n",
      "backLoss:  -0.3938441276550293\n",
      "loss.grad None\n",
      "backLoss:  -0.38400912284851074\n",
      "loss.grad None\n",
      "backLoss:  -0.37566661834716797\n",
      "loss.grad None\n",
      "backLoss:  -0.36858439445495605\n",
      "loss.grad None\n",
      "backLoss:  -0.362565279006958\n",
      "loss.grad None\n",
      "backLoss:  -0.3574509620666504\n",
      "loss.grad None\n",
      "backLoss:  -0.35309886932373047\n",
      "loss.grad None\n",
      "backLoss:  -0.3493926525115967\n",
      "loss.grad None\n",
      "backLoss:  -0.3462374210357666\n",
      "loss.grad None\n",
      "backLoss:  -0.34354567527770996\n",
      "loss.grad None\n",
      "backLoss:  -0.3412466049194336\n",
      "loss.grad None\n",
      "backLoss:  -0.3392770290374756\n",
      "loss.grad None\n",
      "backLoss:  -0.33759570121765137\n",
      "loss.grad None\n",
      "backLoss:  -0.33614492416381836\n",
      "loss.grad None\n",
      "backLoss:  -0.3349025249481201\n",
      "loss.grad None\n",
      "backLoss:  -0.33382582664489746\n",
      "loss.grad None\n",
      "backLoss:  -0.33289194107055664\n",
      "loss.grad None\n",
      "backLoss:  -0.33208227157592773\n",
      "loss.grad None\n",
      "backLoss:  -0.3313770294189453\n",
      "loss.grad None\n",
      "backLoss:  -0.3307616710662842\n",
      "loss.grad None\n",
      "backLoss:  -0.3302195072174072\n",
      "loss.grad None\n",
      "backLoss:  -0.3297388553619385\n",
      "loss.grad None\n",
      "backLoss:  -0.329312801361084\n",
      "loss.grad None\n",
      "backLoss:  -0.3289341926574707\n",
      "loss.grad None\n",
      "backLoss:  -0.3285844326019287\n",
      "loss.grad None\n",
      "backLoss:  -0.32826948165893555\n",
      "loss.grad None\n",
      "backLoss:  -0.3279860019683838\n",
      "loss.grad None\n",
      "backLoss:  -0.3277242183685303\n",
      "loss.grad None\n",
      "backLoss:  -0.32747888565063477\n",
      "loss.grad None\n",
      "backLoss:  -0.3272566795349121\n",
      "loss.grad None\n",
      "backLoss:  -0.32704806327819824\n",
      "loss.grad None\n",
      "backLoss:  -0.3268418312072754\n",
      "loss.grad None\n",
      "backLoss:  -0.32665395736694336\n",
      "loss.grad None\n",
      "backLoss:  -0.32647037506103516\n",
      "loss.grad None\n",
      "backLoss:  -0.3262934684753418\n",
      "loss.grad None\n",
      "backLoss:  -0.3261265754699707\n",
      "loss.grad None\n",
      "backLoss:  -0.32596421241760254\n",
      "loss.grad None\n",
      "backLoss:  -0.3258092403411865\n",
      "loss.grad None\n",
      "backLoss:  -0.3256545066833496\n",
      "loss.grad None\n",
      "backLoss:  -0.3254995346069336\n",
      "loss.grad None\n",
      "backLoss:  -0.32535314559936523\n",
      "loss.grad None\n",
      "backLoss:  -0.32520604133605957\n",
      "loss.grad None\n",
      "backLoss:  -0.3250586986541748\n",
      "loss.grad None\n",
      "backLoss:  -0.32491302490234375\n",
      "loss.grad None\n",
      "backLoss:  -0.32477498054504395\n",
      "loss.grad None\n",
      "backLoss:  -0.32463598251342773\n",
      "loss.grad None\n",
      "backLoss:  -0.3244974613189697\n",
      "loss.grad None\n",
      "backLoss:  -0.32436203956604004\n",
      "loss.grad None\n",
      "backLoss:  -0.32422447204589844\n",
      "loss.grad None\n",
      "backLoss:  -0.32408618927001953\n",
      "loss.grad None\n",
      "Actual Loss:  2.628556966781616\n",
      "backLoss:  -0.32395052909851074\n",
      "loss.grad None\n",
      "backLoss:  -0.32381653785705566\n",
      "loss.grad None\n",
      "backLoss:  -0.323681116104126\n",
      "loss.grad None\n",
      "backLoss:  -0.323544979095459\n",
      "loss.grad None\n",
      "backLoss:  -0.3234117031097412\n",
      "loss.grad None\n",
      "backLoss:  -0.32327747344970703\n",
      "loss.grad None\n",
      "backLoss:  -0.32314372062683105\n",
      "loss.grad None\n",
      "backLoss:  -0.3230125904083252\n",
      "loss.grad None\n",
      "backLoss:  -0.3228721618652344\n",
      "loss.grad None\n",
      "backLoss:  -0.322739839553833\n",
      "loss.grad None\n",
      "backLoss:  -0.32260990142822266\n",
      "loss.grad None\n",
      "backLoss:  -0.32247161865234375\n",
      "loss.grad None\n",
      "backLoss:  -0.32233524322509766\n",
      "loss.grad None\n",
      "backLoss:  -0.32219886779785156\n",
      "loss.grad None\n",
      "backLoss:  -0.32206296920776367\n",
      "loss.grad None\n",
      "backLoss:  -0.3219261169433594\n",
      "loss.grad None\n",
      "backLoss:  -0.32179713249206543\n",
      "loss.grad None\n",
      "backLoss:  -0.32166409492492676\n",
      "loss.grad None\n",
      "backLoss:  -0.32152700424194336\n",
      "loss.grad None\n",
      "backLoss:  -0.3213961124420166\n",
      "loss.grad None\n",
      "backLoss:  -0.3212614059448242\n",
      "loss.grad None\n",
      "backLoss:  -0.32112789154052734\n",
      "loss.grad None\n",
      "backLoss:  -0.32099413871765137\n",
      "loss.grad None\n",
      "backLoss:  -0.3208632469177246\n",
      "loss.grad None\n",
      "backLoss:  -0.32073092460632324\n",
      "loss.grad None\n",
      "backLoss:  -0.3206019401550293\n",
      "loss.grad None\n",
      "backLoss:  -0.32046961784362793\n",
      "loss.grad None\n",
      "backLoss:  -0.3203394412994385\n",
      "loss.grad None\n",
      "backLoss:  -0.32021093368530273\n",
      "loss.grad None\n",
      "backLoss:  -0.3200814723968506\n",
      "loss.grad None\n",
      "backLoss:  -0.3199467658996582\n",
      "loss.grad None\n",
      "backLoss:  -0.3198115825653076\n",
      "loss.grad None\n",
      "backLoss:  -0.31967639923095703\n",
      "loss.grad None\n",
      "backLoss:  -0.31954288482666016\n",
      "loss.grad None\n",
      "backLoss:  -0.319408655166626\n",
      "loss.grad None\n",
      "backLoss:  -0.319277286529541\n",
      "loss.grad None\n",
      "backLoss:  -0.31914401054382324\n",
      "loss.grad None\n",
      "backLoss:  -0.3190135955810547\n",
      "loss.grad None\n",
      "backLoss:  -0.3188817501068115\n",
      "loss.grad None\n",
      "backLoss:  -0.31874895095825195\n",
      "loss.grad None\n",
      "backLoss:  -0.3186192512512207\n",
      "loss.grad None\n",
      "backLoss:  -0.31848835945129395\n",
      "loss.grad None\n",
      "backLoss:  -0.3183579444885254\n",
      "loss.grad None\n",
      "backLoss:  -0.31823039054870605\n",
      "loss.grad None\n",
      "backLoss:  -0.3180994987487793\n",
      "loss.grad None\n",
      "backLoss:  -0.31797099113464355\n",
      "loss.grad None\n",
      "backLoss:  -0.3178391456604004\n",
      "loss.grad None\n",
      "backLoss:  -0.3177034854888916\n",
      "loss.grad None\n",
      "backLoss:  -0.31757116317749023\n",
      "loss.grad None\n",
      "backLoss:  -0.31743860244750977\n",
      "loss.grad None\n",
      "backLoss:  -0.3173041343688965\n",
      "loss.grad None\n",
      "backLoss:  -0.3171722888946533\n",
      "loss.grad None\n",
      "backLoss:  -0.31704139709472656\n",
      "loss.grad None\n",
      "backLoss:  -0.3169112205505371\n",
      "loss.grad None\n",
      "backLoss:  -0.31677961349487305\n",
      "loss.grad None\n",
      "backLoss:  -0.3166491985321045\n",
      "loss.grad None\n",
      "backLoss:  -0.31652045249938965\n",
      "loss.grad None\n",
      "backLoss:  -0.3163902759552002\n",
      "loss.grad None\n",
      "backLoss:  -0.31626081466674805\n",
      "loss.grad None\n",
      "backLoss:  -0.3161332607269287\n",
      "loss.grad None\n",
      "backLoss:  -0.31600379943847656\n",
      "loss.grad None\n",
      "backLoss:  -0.31587815284729004\n",
      "loss.grad None\n",
      "backLoss:  -0.31574416160583496\n",
      "loss.grad None\n",
      "backLoss:  -0.31561732292175293\n",
      "loss.grad None\n",
      "backLoss:  -0.31548190116882324\n",
      "loss.grad None\n",
      "backLoss:  -0.3153510093688965\n",
      "loss.grad None\n",
      "backLoss:  -0.31522035598754883\n",
      "loss.grad None\n",
      "backLoss:  -0.31508827209472656\n",
      "loss.grad None\n",
      "backLoss:  -0.3149564266204834\n",
      "loss.grad None\n",
      "backLoss:  -0.31482648849487305\n",
      "loss.grad None\n",
      "backLoss:  -0.314697265625\n",
      "loss.grad None\n",
      "backLoss:  -0.31456685066223145\n",
      "loss.grad None\n",
      "backLoss:  -0.3144376277923584\n",
      "loss.grad None\n",
      "backLoss:  -0.31430792808532715\n",
      "loss.grad None\n",
      "backLoss:  -0.3141801357269287\n",
      "loss.grad None\n",
      "backLoss:  -0.3140542507171631\n",
      "loss.grad None\n",
      "backLoss:  -0.31392669677734375\n",
      "loss.grad None\n",
      "backLoss:  -0.3137984275817871\n",
      "loss.grad None\n",
      "backLoss:  -0.31366682052612305\n",
      "loss.grad None\n",
      "backLoss:  -0.3135335445404053\n",
      "loss.grad None\n",
      "backLoss:  -0.31341052055358887\n",
      "loss.grad None\n",
      "backLoss:  -0.3132767677307129\n",
      "loss.grad None\n",
      "backLoss:  -0.31314635276794434\n",
      "loss.grad None\n",
      "backLoss:  -0.3130156993865967\n",
      "loss.grad None\n",
      "backLoss:  -0.31288647651672363\n",
      "loss.grad None\n",
      "backLoss:  -0.3127555847167969\n",
      "loss.grad None\n",
      "backLoss:  -0.31262731552124023\n",
      "loss.grad None\n",
      "backLoss:  -0.31249547004699707\n",
      "loss.grad None\n",
      "backLoss:  -0.31236863136291504\n",
      "loss.grad None\n",
      "backLoss:  -0.3122408390045166\n",
      "loss.grad None\n",
      "backLoss:  -0.31211256980895996\n",
      "loss.grad None\n",
      "backLoss:  -0.3119838237762451\n",
      "loss.grad None\n",
      "backLoss:  -0.3118603229522705\n",
      "loss.grad None\n",
      "backLoss:  -0.3117341995239258\n",
      "loss.grad None\n",
      "backLoss:  -0.3116002082824707\n",
      "loss.grad None\n",
      "backLoss:  -0.3114762306213379\n",
      "loss.grad None\n",
      "backLoss:  -0.3113439083099365\n",
      "loss.grad None\n",
      "backLoss:  -0.31121301651000977\n",
      "loss.grad None\n",
      "backLoss:  -0.3110842704772949\n",
      "loss.grad None\n",
      "backLoss:  -0.31095314025878906\n",
      "loss.grad None\n",
      "Actual Loss:  2.6275291442871094\n",
      "backLoss:  -0.3108236789703369\n",
      "loss.grad None\n",
      "backLoss:  -0.31069517135620117\n",
      "loss.grad None\n",
      "backLoss:  -0.31056785583496094\n",
      "loss.grad None\n",
      "backLoss:  -0.3104395866394043\n",
      "loss.grad None\n",
      "backLoss:  -0.31031250953674316\n",
      "loss.grad None\n",
      "backLoss:  -0.3101832866668701\n",
      "loss.grad None\n",
      "backLoss:  -0.3100578784942627\n",
      "loss.grad None\n",
      "backLoss:  -0.30993151664733887\n",
      "loss.grad None\n",
      "backLoss:  -0.30980610847473145\n",
      "loss.grad None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda3\\envs\\py39\\lib\\site-packages\\torch\\_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten\\src\\ATen/core/TensorBody.h:417.)\n",
      "  return self._grad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backLoss:  -0.3096797466278076\n",
      "loss.grad None\n",
      "backLoss:  -0.3095555305480957\n",
      "loss.grad None\n",
      "backLoss:  -0.30942392349243164\n",
      "loss.grad None\n",
      "backLoss:  -0.3092920780181885\n",
      "loss.grad None\n",
      "backLoss:  -0.3091609477996826\n",
      "loss.grad None\n",
      "backLoss:  -0.309039831161499\n",
      "loss.grad None\n",
      "backLoss:  -0.308910608291626\n",
      "loss.grad None\n",
      "backLoss:  -0.30878353118896484\n",
      "loss.grad None\n",
      "backLoss:  -0.3086535930633545\n",
      "loss.grad None\n",
      "backLoss:  -0.30852556228637695\n",
      "loss.grad None\n",
      "backLoss:  -0.3083982467651367\n",
      "loss.grad None\n",
      "backLoss:  -0.3082711696624756\n",
      "loss.grad None\n",
      "backLoss:  -0.30814552307128906\n",
      "loss.grad None\n",
      "backLoss:  -0.3080179691314697\n",
      "loss.grad None\n",
      "backLoss:  -0.3078925609588623\n",
      "loss.grad None\n",
      "backLoss:  -0.3077671527862549\n",
      "loss.grad None\n",
      "backLoss:  -0.30764341354370117\n",
      "loss.grad None\n",
      "backLoss:  -0.30751848220825195\n",
      "loss.grad None\n",
      "backLoss:  -0.3073880672454834\n",
      "loss.grad None\n",
      "backLoss:  -0.30725812911987305\n",
      "loss.grad None\n",
      "backLoss:  -0.3071291446685791\n",
      "loss.grad None\n",
      "backLoss:  -0.30700016021728516\n",
      "loss.grad None\n",
      "backLoss:  -0.3068721294403076\n",
      "loss.grad None\n",
      "backLoss:  -0.3067436218261719\n",
      "loss.grad None\n",
      "backLoss:  -0.30661535263061523\n",
      "loss.grad None\n",
      "backLoss:  -0.3064875602722168\n",
      "loss.grad None\n",
      "backLoss:  -0.3063621520996094\n",
      "loss.grad None\n",
      "backLoss:  -0.30623555183410645\n",
      "loss.grad None\n",
      "backLoss:  -0.3061084747314453\n",
      "loss.grad None\n",
      "backLoss:  -0.3059835433959961\n",
      "loss.grad None\n",
      "backLoss:  -0.30585670471191406\n",
      "loss.grad None\n",
      "backLoss:  -0.30573368072509766\n",
      "loss.grad None\n",
      "backLoss:  -0.30560898780822754\n",
      "loss.grad None\n",
      "backLoss:  -0.3054835796356201\n",
      "loss.grad None\n",
      "backLoss:  -0.3053593635559082\n",
      "loss.grad None\n",
      "backLoss:  -0.3052363395690918\n",
      "loss.grad None\n",
      "backLoss:  -0.3051156997680664\n",
      "loss.grad None\n",
      "backLoss:  -0.30498600006103516\n",
      "loss.grad None\n",
      "backLoss:  -0.3048574924468994\n",
      "loss.grad None\n",
      "backLoss:  -0.3047306537628174\n",
      "loss.grad None\n",
      "backLoss:  -0.30460524559020996\n",
      "loss.grad None\n",
      "backLoss:  -0.30447864532470703\n",
      "loss.grad None\n",
      "backLoss:  -0.3043508529663086\n",
      "loss.grad None\n",
      "backLoss:  -0.30422377586364746\n",
      "loss.grad None\n",
      "backLoss:  -0.30410075187683105\n",
      "loss.grad None\n",
      "backLoss:  -0.30397629737854004\n",
      "loss.grad None\n",
      "backLoss:  -0.3038501739501953\n",
      "loss.grad None\n",
      "backLoss:  -0.3037254810333252\n",
      "loss.grad None\n",
      "backLoss:  -0.3036019802093506\n",
      "loss.grad None\n",
      "backLoss:  -0.3034787178039551\n",
      "loss.grad None\n",
      "backLoss:  -0.30335545539855957\n",
      "loss.grad None\n",
      "backLoss:  -0.30323219299316406\n",
      "loss.grad None\n",
      "backLoss:  -0.3031039237976074\n",
      "loss.grad None\n",
      "backLoss:  -0.3029766082763672\n",
      "loss.grad None\n",
      "backLoss:  -0.30284905433654785\n",
      "loss.grad None\n",
      "backLoss:  -0.3027219772338867\n",
      "loss.grad None\n",
      "backLoss:  -0.3025956153869629\n",
      "loss.grad None\n",
      "backLoss:  -0.30246806144714355\n",
      "loss.grad None\n",
      "backLoss:  -0.30234336853027344\n",
      "loss.grad None\n",
      "backLoss:  -0.3022177219390869\n",
      "loss.grad None\n",
      "backLoss:  -0.3020930290222168\n",
      "loss.grad None\n",
      "backLoss:  -0.3019695281982422\n",
      "loss.grad None\n",
      "backLoss:  -0.30184412002563477\n",
      "loss.grad None\n",
      "backLoss:  -0.30172014236450195\n",
      "loss.grad None\n",
      "backLoss:  -0.30159807205200195\n",
      "loss.grad None\n",
      "backLoss:  -0.30147480964660645\n",
      "loss.grad None\n",
      "backLoss:  -0.30135273933410645\n",
      "loss.grad None\n",
      "backLoss:  -0.30122900009155273\n",
      "loss.grad None\n",
      "backLoss:  -0.30110788345336914\n",
      "loss.grad None\n",
      "backLoss:  -0.30098915100097656\n",
      "loss.grad None\n",
      "backLoss:  -0.3008608818054199\n",
      "loss.grad None\n",
      "backLoss:  -0.3007330894470215\n",
      "loss.grad None\n",
      "backLoss:  -0.30060505867004395\n",
      "loss.grad None\n",
      "backLoss:  -0.30048060417175293\n",
      "loss.grad None\n",
      "backLoss:  -0.3003549575805664\n",
      "loss.grad None\n",
      "backLoss:  -0.3002297878265381\n",
      "loss.grad None\n",
      "backLoss:  -0.30010485649108887\n",
      "loss.grad None\n",
      "backLoss:  -0.29998326301574707\n",
      "loss.grad None\n",
      "backLoss:  -0.29986047744750977\n",
      "loss.grad None\n",
      "backLoss:  -0.29973626136779785\n",
      "loss.grad None\n",
      "backLoss:  -0.29961228370666504\n",
      "loss.grad None\n",
      "backLoss:  -0.29948997497558594\n",
      "loss.grad None\n",
      "backLoss:  -0.29936861991882324\n",
      "loss.grad None\n",
      "backLoss:  -0.29924726486206055\n",
      "loss.grad None\n",
      "backLoss:  -0.29912805557250977\n",
      "loss.grad None\n",
      "backLoss:  -0.29900479316711426\n",
      "loss.grad None\n",
      "backLoss:  -0.2988779544830322\n",
      "loss.grad None\n",
      "backLoss:  -0.2987534999847412\n",
      "loss.grad None\n",
      "backLoss:  -0.2986280918121338\n",
      "loss.grad None\n",
      "backLoss:  -0.29850172996520996\n",
      "loss.grad None\n",
      "backLoss:  -0.29837608337402344\n",
      "loss.grad None\n",
      "Actual Loss:  2.626582145690918\n",
      "backLoss:  -0.29825258255004883\n",
      "loss.grad None\n",
      "backLoss:  -0.2981283664703369\n",
      "loss.grad None\n",
      "backLoss:  -0.2980060577392578\n",
      "loss.grad None\n",
      "backLoss:  -0.2978830337524414\n",
      "loss.grad None\n",
      "backLoss:  -0.2977583408355713\n",
      "loss.grad None\n",
      "backLoss:  -0.297635555267334\n",
      "loss.grad None\n",
      "backLoss:  -0.2975132465362549\n",
      "loss.grad None\n",
      "backLoss:  -0.2973926067352295\n",
      "loss.grad None\n",
      "backLoss:  -0.2972705364227295\n",
      "loss.grad None\n",
      "backLoss:  -0.2971501350402832\n",
      "loss.grad None\n",
      "backLoss:  -0.2970268726348877\n",
      "loss.grad None\n",
      "backLoss:  -0.29690980911254883\n",
      "loss.grad None\n",
      "backLoss:  -0.29679012298583984\n",
      "loss.grad None\n",
      "backLoss:  -0.2966642379760742\n",
      "loss.grad None\n",
      "backLoss:  -0.2965390682220459\n",
      "loss.grad None\n",
      "backLoss:  -0.2964136600494385\n",
      "loss.grad None\n",
      "backLoss:  -0.29628920555114746\n",
      "loss.grad None\n",
      "backLoss:  -0.29616618156433105\n",
      "loss.grad None\n",
      "backLoss:  -0.29604315757751465\n",
      "loss.grad None\n",
      "backLoss:  -0.29591870307922363\n",
      "loss.grad None\n",
      "backLoss:  -0.29579758644104004\n",
      "loss.grad None\n",
      "backLoss:  -0.29567456245422363\n",
      "loss.grad None\n",
      "backLoss:  -0.29555392265319824\n",
      "loss.grad None\n",
      "backLoss:  -0.29543352127075195\n",
      "loss.grad None\n",
      "backLoss:  -0.29531025886535645\n",
      "loss.grad None\n",
      "backLoss:  -0.2951929569244385\n",
      "loss.grad None\n",
      "backLoss:  -0.2950713634490967\n",
      "loss.grad None\n",
      "backLoss:  -0.2949519157409668\n",
      "loss.grad None\n",
      "backLoss:  -0.2948329448699951\n",
      "loss.grad None\n",
      "backLoss:  -0.29471445083618164\n",
      "loss.grad None\n",
      "backLoss:  -0.2945888042449951\n",
      "loss.grad None\n",
      "backLoss:  -0.29447388648986816\n",
      "loss.grad None\n",
      "backLoss:  -0.29434847831726074\n",
      "loss.grad None\n",
      "backLoss:  -0.29422569274902344\n",
      "loss.grad None\n",
      "backLoss:  -0.2941014766693115\n",
      "loss.grad None\n",
      "backLoss:  -0.2939798831939697\n",
      "loss.grad None\n",
      "backLoss:  -0.29385828971862793\n",
      "loss.grad None\n",
      "backLoss:  -0.2937352657318115\n",
      "loss.grad None\n",
      "backLoss:  -0.2936127185821533\n",
      "loss.grad None\n",
      "backLoss:  -0.2934913635253906\n",
      "loss.grad None\n",
      "backLoss:  -0.29337358474731445\n",
      "loss.grad None\n",
      "backLoss:  -0.29325389862060547\n",
      "loss.grad None\n",
      "backLoss:  -0.2931327819824219\n",
      "loss.grad None\n",
      "backLoss:  -0.2930135726928711\n",
      "loss.grad None\n",
      "backLoss:  -0.2928926944732666\n",
      "loss.grad None\n",
      "backLoss:  -0.2927742004394531\n",
      "loss.grad None\n",
      "backLoss:  -0.29265713691711426\n",
      "loss.grad None\n",
      "backLoss:  -0.29253458976745605\n",
      "loss.grad None\n",
      "backLoss:  -0.29241108894348145\n",
      "loss.grad None\n",
      "backLoss:  -0.2922859191894531\n",
      "loss.grad None\n",
      "backLoss:  -0.29216480255126953\n",
      "loss.grad None\n",
      "backLoss:  -0.292041540145874\n",
      "loss.grad None\n",
      "backLoss:  -0.29192018508911133\n",
      "loss.grad None\n",
      "backLoss:  -0.2917978763580322\n",
      "loss.grad None\n",
      "backLoss:  -0.29167628288269043\n",
      "loss.grad None\n",
      "backLoss:  -0.29155516624450684\n",
      "loss.grad None\n",
      "backLoss:  -0.29143595695495605\n",
      "loss.grad None\n",
      "backLoss:  -0.2913169860839844\n",
      "loss.grad None\n",
      "backLoss:  -0.2911958694458008\n",
      "loss.grad None\n",
      "backLoss:  -0.2910759449005127\n",
      "loss.grad None\n",
      "backLoss:  -0.2909581661224365\n",
      "loss.grad None\n",
      "backLoss:  -0.29083991050720215\n",
      "loss.grad None\n",
      "backLoss:  -0.2907218933105469\n",
      "loss.grad None\n",
      "backLoss:  -0.2906041145324707\n",
      "loss.grad None\n",
      "backLoss:  -0.29048776626586914\n",
      "loss.grad None\n",
      "backLoss:  -0.29036450386047363\n",
      "loss.grad None\n",
      "backLoss:  -0.29024243354797363\n",
      "loss.grad None\n",
      "backLoss:  -0.29011988639831543\n",
      "loss.grad None\n",
      "backLoss:  -0.2900047302246094\n",
      "loss.grad None\n",
      "backLoss:  -0.2898828983306885\n",
      "loss.grad None\n",
      "backLoss:  -0.2897610664367676\n",
      "loss.grad None\n",
      "backLoss:  -0.2896413803100586\n",
      "loss.grad None\n",
      "backLoss:  -0.2895214557647705\n",
      "loss.grad None\n",
      "backLoss:  -0.2894020080566406\n",
      "loss.grad None\n",
      "backLoss:  -0.2892796993255615\n",
      "loss.grad None\n",
      "backLoss:  -0.28916192054748535\n",
      "loss.grad None\n",
      "backLoss:  -0.2890450954437256\n",
      "loss.grad None\n",
      "backLoss:  -0.2889268398284912\n",
      "loss.grad None\n",
      "backLoss:  -0.28880763053894043\n",
      "loss.grad None\n",
      "backLoss:  -0.28869080543518066\n",
      "loss.grad None\n",
      "backLoss:  -0.2885732650756836\n",
      "loss.grad None\n",
      "backLoss:  -0.28845834732055664\n",
      "loss.grad None\n",
      "backLoss:  -0.28833556175231934\n",
      "loss.grad None\n",
      "backLoss:  -0.28821444511413574\n",
      "loss.grad None\n",
      "backLoss:  -0.2880897521972656\n",
      "loss.grad None\n",
      "backLoss:  -0.2879760265350342\n",
      "loss.grad None\n",
      "backLoss:  -0.2878549098968506\n",
      "loss.grad None\n",
      "backLoss:  -0.2877352237701416\n",
      "loss.grad None\n",
      "backLoss:  -0.2876160144805908\n",
      "loss.grad None\n",
      "backLoss:  -0.2874941825866699\n",
      "loss.grad None\n",
      "backLoss:  -0.28737545013427734\n",
      "loss.grad None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backLoss:  -0.28725743293762207\n",
      "loss.grad None\n",
      "backLoss:  -0.2871401309967041\n",
      "loss.grad None\n",
      "backLoss:  -0.2870199680328369\n",
      "loss.grad None\n",
      "backLoss:  -0.28690147399902344\n",
      "loss.grad None\n",
      "backLoss:  -0.2867856025695801\n",
      "loss.grad None\n",
      "backLoss:  -0.2866690158843994\n",
      "loss.grad None\n",
      "backLoss:  -0.28655338287353516\n",
      "loss.grad None\n",
      "backLoss:  -0.2864367961883545\n",
      "loss.grad None\n",
      "backLoss:  -0.2863197326660156\n",
      "loss.grad None\n",
      "Actual Loss:  2.6257102489471436\n",
      "backLoss:  -0.2862060070037842\n",
      "loss.grad None\n",
      "backLoss:  -0.2860848903656006\n",
      "loss.grad None\n",
      "backLoss:  -0.2859654426574707\n",
      "loss.grad None\n",
      "backLoss:  -0.2858450412750244\n",
      "loss.grad None\n",
      "backLoss:  -0.285724401473999\n",
      "loss.grad None\n",
      "backLoss:  -0.28560543060302734\n",
      "loss.grad None\n",
      "backLoss:  -0.28548669815063477\n",
      "loss.grad None\n",
      "backLoss:  -0.2853670120239258\n",
      "loss.grad None\n",
      "backLoss:  -0.2852482795715332\n",
      "loss.grad None\n",
      "backLoss:  -0.28513097763061523\n",
      "loss.grad None\n",
      "backLoss:  -0.28501272201538086\n",
      "loss.grad None\n",
      "backLoss:  -0.2848975658416748\n",
      "loss.grad None\n",
      "backLoss:  -0.28478026390075684\n",
      "loss.grad None\n",
      "backLoss:  -0.28466367721557617\n",
      "loss.grad None\n",
      "backLoss:  -0.2845466136932373\n",
      "loss.grad None\n",
      "backLoss:  -0.28443217277526855\n",
      "loss.grad None\n",
      "backLoss:  -0.2843184471130371\n",
      "loss.grad None\n",
      "backLoss:  -0.28420352935791016\n",
      "loss.grad None\n",
      "backLoss:  -0.28408241271972656\n",
      "loss.grad None\n",
      "backLoss:  -0.28396034240722656\n",
      "loss.grad None\n",
      "backLoss:  -0.28384995460510254\n",
      "loss.grad None\n",
      "backLoss:  -0.28373003005981445\n",
      "loss.grad None\n",
      "backLoss:  -0.2836117744445801\n",
      "loss.grad None\n",
      "backLoss:  -0.2834925651550293\n",
      "loss.grad None\n",
      "backLoss:  -0.2833735942840576\n",
      "loss.grad None\n",
      "backLoss:  -0.28325605392456055\n",
      "loss.grad None\n",
      "backLoss:  -0.2831408977508545\n",
      "loss.grad None\n",
      "backLoss:  -0.283022403717041\n",
      "loss.grad None\n",
      "backLoss:  -0.28290557861328125\n",
      "loss.grad None\n",
      "backLoss:  -0.2827897071838379\n",
      "loss.grad None\n",
      "backLoss:  -0.28267502784729004\n",
      "loss.grad None\n",
      "backLoss:  -0.2825582027435303\n",
      "loss.grad None\n",
      "backLoss:  -0.28244566917419434\n",
      "loss.grad None\n",
      "backLoss:  -0.2823295593261719\n",
      "loss.grad None\n",
      "backLoss:  -0.2822153568267822\n",
      "loss.grad None\n",
      "backLoss:  -0.2821028232574463\n",
      "loss.grad None\n",
      "backLoss:  -0.281982421875\n",
      "loss.grad None\n",
      "backLoss:  -0.2818639278411865\n",
      "loss.grad None\n",
      "backLoss:  -0.28174567222595215\n",
      "loss.grad None\n",
      "backLoss:  -0.28162503242492676\n",
      "loss.grad None\n",
      "backLoss:  -0.2815091609954834\n",
      "loss.grad None\n",
      "backLoss:  -0.28139162063598633\n",
      "loss.grad None\n",
      "backLoss:  -0.28127431869506836\n",
      "loss.grad None\n",
      "backLoss:  -0.2811570167541504\n",
      "loss.grad None\n",
      "backLoss:  -0.28104090690612793\n",
      "loss.grad None\n",
      "backLoss:  -0.28092288970947266\n",
      "loss.grad None\n",
      "backLoss:  -0.2808091640472412\n",
      "loss.grad None\n",
      "backLoss:  -0.28069305419921875\n",
      "loss.grad None\n",
      "backLoss:  -0.2805776596069336\n",
      "loss.grad None\n",
      "backLoss:  -0.28046512603759766\n",
      "loss.grad None\n",
      "backLoss:  -0.2803490161895752\n",
      "loss.grad None\n",
      "backLoss:  -0.28023505210876465\n",
      "loss.grad None\n",
      "backLoss:  -0.2801222801208496\n",
      "loss.grad None\n",
      "backLoss:  -0.28000831604003906\n",
      "loss.grad None\n",
      "backLoss:  -0.27989625930786133\n",
      "loss.grad None\n",
      "backLoss:  -0.27977728843688965\n",
      "loss.grad None\n",
      "backLoss:  -0.2796597480773926\n",
      "loss.grad None\n",
      "backLoss:  -0.2795436382293701\n",
      "loss.grad None\n",
      "backLoss:  -0.27942466735839844\n",
      "loss.grad None\n",
      "backLoss:  -0.27930736541748047\n",
      "loss.grad None\n",
      "backLoss:  -0.2791900634765625\n",
      "loss.grad None\n",
      "backLoss:  -0.27907466888427734\n",
      "loss.grad None\n",
      "backLoss:  -0.2789597511291504\n",
      "loss.grad None\n",
      "backLoss:  -0.27884459495544434\n",
      "loss.grad None\n",
      "backLoss:  -0.2787292003631592\n",
      "loss.grad None\n",
      "backLoss:  -0.2786135673522949\n",
      "loss.grad None\n",
      "backLoss:  -0.2785005569458008\n",
      "loss.grad None\n",
      "backLoss:  -0.27838921546936035\n",
      "loss.grad None\n",
      "backLoss:  -0.2782745361328125\n",
      "loss.grad None\n",
      "backLoss:  -0.27816128730773926\n",
      "loss.grad None\n",
      "backLoss:  -0.2780478000640869\n",
      "loss.grad None\n",
      "backLoss:  -0.2779369354248047\n",
      "loss.grad None\n",
      "backLoss:  -0.27782535552978516\n",
      "loss.grad None\n",
      "backLoss:  -0.2777085304260254\n",
      "loss.grad None\n",
      "backLoss:  -0.2775890827178955\n",
      "loss.grad None\n",
      "backLoss:  -0.27747201919555664\n",
      "loss.grad None\n",
      "backLoss:  -0.2773549556732178\n",
      "loss.grad None\n",
      "backLoss:  -0.2772402763366699\n",
      "loss.grad None\n",
      "backLoss:  -0.27712535858154297\n",
      "loss.grad None\n",
      "backLoss:  -0.2770094871520996\n",
      "loss.grad None\n",
      "backLoss:  -0.27689290046691895\n",
      "loss.grad None\n",
      "backLoss:  -0.2767775058746338\n",
      "loss.grad None\n",
      "backLoss:  -0.27666354179382324\n",
      "loss.grad None\n",
      "backLoss:  -0.27655029296875\n",
      "loss.grad None\n",
      "backLoss:  -0.27643656730651855\n",
      "loss.grad None\n",
      "backLoss:  -0.2763235569000244\n",
      "loss.grad None\n",
      "backLoss:  -0.2762105464935303\n",
      "loss.grad None\n",
      "backLoss:  -0.27609896659851074\n",
      "loss.grad None\n",
      "backLoss:  -0.2759864330291748\n",
      "loss.grad None\n",
      "backLoss:  -0.2758762836456299\n",
      "loss.grad None\n",
      "backLoss:  -0.27576351165771484\n",
      "loss.grad None\n",
      "backLoss:  -0.2756521701812744\n",
      "loss.grad None\n",
      "backLoss:  -0.27553725242614746\n",
      "loss.grad None\n",
      "backLoss:  -0.2754206657409668\n",
      "loss.grad None\n",
      "backLoss:  -0.27530550956726074\n",
      "loss.grad None\n",
      "backLoss:  -0.2751893997192383\n",
      "loss.grad None\n",
      "backLoss:  -0.27507448196411133\n",
      "loss.grad None\n",
      "backLoss:  -0.2749598026275635\n",
      "loss.grad None\n",
      "backLoss:  -0.27484631538391113\n",
      "loss.grad None\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    y_pred = simple_network(x) # function which computes wx + b\n",
    "    loss = loss_fn(y,y_pred)   # calculates sum of the squared differences of y and y_pred   \n",
    "    if i % 100 == 0: \n",
    "        print(\"Actual Loss: \",loss.item())\n",
    "    optimize(learning_rate)    # Adjust w,b to minimize the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dbc83f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
